\documentclass[14pt]{report}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{cmbright}
\usepackage{euler}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage[margin=2.5cm]{geometry}
\usepackage[applemac]{inputenc}
\usepackage[english]{babel}
\setlength{\parindent}{0pt}
\onehalfspace

\begin{document}
\textbf{{Review of Linear Algebra: Questions \& Solutions}}\\
\thispagestyle{empty}


\begin{enumerate}
\item Every plane in $\mathbb{R}^n$ is a subspace of $\mathbb{R}^n$.\\
\textbf{FALSE.}  Zero must be an element of a vector space. 

\item There are $4$ linearly independent vectors in $\mathbb{R}^3$. \\
\textbf{FALSE.} The dimension of a vector space $\mathbb{V}$
  is defined as the number of elements in any basis of $\mathbb{V}$, or
  equivalently: $dim(\mathbb{V})=$ maximum number of linearly independent
  vectors.

\item If $Ax=b$ for $A \in \mathbb{R}^{m\times n}$, $x\in\mathbb{R}^n$, and
  $b\in\mathbb{R}^m$, then $b$ is a linear combination of the columns of $A$.\\
  \textbf{TRUE.} First, note that the product
  $Ae_1$ is equal to $a_1$, the first column of $A$.
  Similarly for any cannonical vector $e_k$ we obtain:
\[\left[\begin{array}{ccc}a_{11}&\cdots&a_{1n}\\a_{21}&&a_{2n}\\\vdots&&\vdots\\a_{m1}&\cdots&a_{mn}\end{array}\right]\left[\begin{array}{c}0\\\vdots\\1\\\vdots\end{array}\right]=\left[\begin{array}{c}a_{1k}\\a_{2k}\\\vdots\\a_{mk}\end{array}\right]=a_k.\]
        That is, the matrix $A$ applied to the $k$-th cannonical vector results
        in the $k$-th column of the matrix $A$. Now, if we express any vector
        $x$ as the linear combination of the basis vectors
        $(x=x_1e_1+\cdots+x_ne_n)$ we can see that the product $Ax$ is a
        linear combination of the columns of $A$ with coefficients given by
        the entries of the vector $x$. 

\item If $A^2=0$ then A is not invertible.\\
  \textbf{TRUE.} We know:$det(A^2)=det(A)^2=0\Rightarrow det(A)=0\Rightarrow A$
  is not invertible.


\item The rank $r$ of the $n$ by $n$ matrix $A=[a_{ij}]$ where $a_{ij}=i+j$ is
  $r=n$.\\
  \textbf{FALSE.} We find a counterexample by looking at the matrix in
  $\mathbb{R}^{3\times 3}$, we
have\[A=\left[\begin{array}{ccc}2&3&4\\3&4&5\\4&5&6\end{array}\right]\sim\left[\begin{array}{ccc}2&3&4\\1&1&1\\1&1&1\end{array}\right]\Rightarrow
rank(A)\neq3\] where we have obtained the second matrix by subtracting the
$1st$ row from the $2nd$ row and the $2nd$ row from the $3rd$ row. (elementary
operations).



%\item If $A$ and $B$ have rank $3$ then $A+B$ has rank at most $6$. 

%\quad \textbf{TRUE} $\Box$ \quad\textbf{FALSE} $\Box$ 
 

\item The inverse of an upper triangular matrix is upper triangular.\\
  \textbf{TRUE.}


\item For every  matrix $A$ with eigenvectors $v_1, v_2$, the sum $v_1 + v_2$ is an eigenvector of $A$. 

\quad \textbf{TRUE} $\Box$ \quad\textbf{FALSE} $\Box$ 

\item For all $A,B \in \mathbb{R}^{n \times n}$ with $n >1$ it holds that $det(2AB^{-1})=2det(A)det(B^{-1})$. 

\quad \textbf{TRUE} $\Box$ \quad\textbf{FALSE} $\Box$ 

\item For all $A,B \in \mathbb{R}^{n \times n}$ with $n >1$ it holds that $det(A+B)=det(A)+det(B)$.

 \quad \textbf{TRUE} $\Box$ \quad\textbf{FALSE} $\Box$ 


\item Two eigenvectors of a matrix $A$ corresponding to different eigenvalues  are linearly independent.

 \quad \textbf{TRUE} $\Box$ \quad\textbf{FALSE} $\Box$ 

\item A set of vectors that are pairwise orthogonal is 
  linearly independent. 

\quad \textbf{TRUE} $\Box$ \quad\textbf{FALSE} $\Box$ 


\item if $A=[a_{ij}]\in\mathbb{R}^{3\times 3}$, and $E=\left[\begin{array}{ccc}
  1&2&0\\0&3&0\\0&2&1\end{array}\right]$ then the product $EA$ equals...\\

     $\Box$ the matrix formed by adding twice row 2 to each row of $A$.\\
     $\Box$ the matrix formed by adding twice column 2 to each column of $A$. 


\item Let $A\in\mathbb{R}^{m\times n}$ represent a linear transformation
  $\mathcal{A}:\mathcal{V}\mapsto \mathcal{W}$. What is the dimension of $\mathcal{V}$?
What is the dimension of $\mathcal{W}$? Write down the rank-nullity theorem.

% \quad \textbf{TRUE} $\Box$ \quad\textbf{FALSE} $\Box$ \\

\item List all the matrix factorizations that you know.


%\item Let $B$ be the $4\times4$ matrix $B=\left[\begin{array}{cccc}
%  1&5&7&3\\8&9&0&4\\4&2&1&7\\2&3&5&6\end{array}\right]$ to which we apply the following operations:
%        \begin{enumerate}
%          \item[(a)] exchange rows 1 \& 4.
%          \item[(b)] add row 3 to row 2.
%          \item[(c)] exchange rows 1 \& 3.
%          \item[(d)] repplace column 1 by column 4.
%          \item[(e)] delete row 4.  
%        \end{enumerate}
%(i) Write the result as a product of 6 matrices.\\
%(ii) Write the result as a product $ABC$ (same $B$) of three matrices.
  \end{enumerate}
  
\begin{figure}
  \begin{center}
    \includegraphics[scale=0.5]{fry2.jpg}\\
    \includegraphics[scale=0.13]{chan.png}
  \end{center}
\end{figure}

\end{document}
